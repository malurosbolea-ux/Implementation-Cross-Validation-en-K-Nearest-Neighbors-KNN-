# ğŸ¯ ImplementaciÃ³n de Cross-Validation en K-Nearest Neighbors (KNN)

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Machine%20Learning-orange.svg)
![Status](https://img.shields.io/badge/Status-Completed-success.svg)
![License](https://img.shields.io/badge/License-MIT-purple.svg)

**OptimizaciÃ³n de hiperparÃ¡metros mediante validaciÃ³n cruzada en clasificadores K-NN**

[Ver AnÃ¡lisis Completo](./Analisis_Completo_Cross_Validation_KNN.docx) â€¢ [Notebook](./implementaciÃ³n_cross_validation.ipynb)

</div>

---

## ğŸ“‹ DescripciÃ³n del proyecto

Este proyecto implementa y evalÃºa el algoritmo **K-Nearest Neighbors (KNN)** utilizando **validaciÃ³n cruzada (cross-validation)** para clasificar especies de flores del famoso dataset Iris. El objetivo principal es demostrar las ventajas de la validaciÃ³n cruzada frente a una simple divisiÃ³n train/test y encontrar el valor Ã³ptimo del hiperparÃ¡metro `k` (nÃºmero de vecinos).

A travÃ©s de este anÃ¡lisis, exploro cÃ³mo diferentes valores de `k` afectan el rendimiento del modelo y cÃ³mo la validaciÃ³n cruzada nos proporciona una evaluaciÃ³n mÃ¡s robusta y confiable del desempeÃ±o del algoritmo.

## ğŸ¯ Objetivos

- âœ… Implementar el algoritmo K-NN desde cero usando Scikit-learn
- âœ… Aplicar validaciÃ³n cruzada (K-Fold Cross-Validation) para evaluar el modelo
- âœ… Comparar cross-validation vs. train/test split tradicional
- âœ… Identificar el valor Ã³ptimo de `k` mediante anÃ¡lisis exhaustivo
- âœ… Visualizar el rendimiento del modelo con diferentes configuraciones
- âœ… Analizar mÃ©tricas de clasificaciÃ³n (accuracy, precision, recall, F1-score)

## ğŸ” Â¿Por quÃ© Cross-Validation?

La validaciÃ³n cruzada es superior a una simple divisiÃ³n train/test porque:

1. **Mayor robustez**: Utiliza todos los datos tanto para entrenamiento como para validaciÃ³n
2. **Reduce el sesgo**: Evita la dependencia de una Ãºnica particiÃ³n aleatoria
3. **Mejor estimaciÃ³n**: Proporciona una medida mÃ¡s precisa del rendimiento real del modelo
4. **Detecta overfitting**: Identifica si el modelo generaliza bien a datos no vistos
5. **OptimizaciÃ³n confiable**: Permite seleccionar hiperparÃ¡metros de forma mÃ¡s segura

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Python 3.8+** - Lenguaje de programaciÃ³n
- **NumPy** - Operaciones numÃ©ricas y arrays
- **Pandas** - ManipulaciÃ³n y anÃ¡lisis de datos
- **Scikit-learn** - Algoritmos de machine learning y validaciÃ³n cruzada
- **Matplotlib & Seaborn** - VisualizaciÃ³n de datos y resultados
- **Jupyter Notebook** - Entorno de desarrollo interactivo

## ğŸ“Š Dataset

Este proyecto utiliza el **Iris Dataset**, uno de los datasets mÃ¡s conocidos en machine learning:

- **150 muestras** de flores Iris
- **3 especies**: Setosa, Versicolor, Virginica
- **4 caracterÃ­sticas**: Longitud y ancho del sÃ©palo, longitud y ancho del pÃ©talo
- **Problema**: ClasificaciÃ³n multiclase

El dataset es ideal para demostrar tÃ©cnicas de validaciÃ³n porque:
- Es pequeÃ±o pero representativo
- Tiene clases balanceadas
- Presenta caracterÃ­sticas con diferentes escalas
- Es ampliamente utilizado como benchmark

## ğŸš€ Estructura del proyecto

```
ğŸ“¦ Implementation-Cross-Validation-KNN
â”œâ”€â”€ ğŸ““ implementaciÃ³n_cross_validation.ipynb    # Notebook principal con cÃ³digo
â”œâ”€â”€ ğŸ“„ Analisis_Completo_Cross_Validation_KNN.docx    # AnÃ¡lisis detallado y resultados
â”œâ”€â”€ ğŸ“‹ README.md                                 # Este archivo
â””â”€â”€ ğŸ“Š visualizations/                           # GrÃ¡ficos generados (si aplica)
```

## ğŸ’¡ MetodologÃ­a

### 1. PreparaciÃ³n de datos
- Carga del dataset Iris
- ExploraciÃ³n de caracterÃ­sticas
- NormalizaciÃ³n/estandarizaciÃ³n de features

### 2. ImplementaciÃ³n de KNN
- ConfiguraciÃ³n del clasificador K-Nearest Neighbors
- Prueba con diferentes valores de `k` (1, 3, 5, 7, 9, 11, 15, 20)
- ImplementaciÃ³n de mÃ©tricas de distancia (Euclidiana)

### 3. ValidaciÃ³n Cruzada
- **K-Fold Cross-Validation** con k=5 y k=10
- CÃ¡lculo de mÃ©tricas promedio y desviaciÃ³n estÃ¡ndar
- AnÃ¡lisis de variabilidad entre folds

### 4. ComparaciÃ³n de enfoques
- Train/Test Split tradicional (70/30)
- Cross-Validation (5-fold y 10-fold)
- AnÃ¡lisis de diferencias en las mÃ©tricas

### 5. SelecciÃ³n del mejor modelo
- EvaluaciÃ³n de accuracy, precision, recall y F1-score
- IdentificaciÃ³n del `k` Ã³ptimo
- AnÃ¡lisis de trade-offs entre sesgo y varianza

## ğŸ“ˆ Resultados principales

Los resultados completos y visualizaciones se encuentran en el [anÃ¡lisis detallado](./Analisis_Completo_Cross_Validation_KNN.docx), pero algunos hallazgos clave incluyen:

- ğŸ¯ **Mejor accuracy alcanzada**: ~97-98% con k Ã³ptimo
- ğŸ“Š **K Ã³ptimo identificado**: Entre 3-7 vecinos (verificar en anÃ¡lisis)
- âš–ï¸ **Cross-validation vs Train/Test**: CV muestra menor varianza en las predicciones
- ğŸ”„ **Estabilidad del modelo**: Mayor consistencia con 10-fold CV
- ğŸ“‰ **Overfitting**: Detectado con valores muy bajos de k (k=1)

## ğŸ¨ Visualizaciones

El proyecto incluye mÃºltiples visualizaciones:

- ğŸ“Š GrÃ¡fico de accuracy vs. nÃºmero de vecinos (k)
- ğŸ“ˆ Curvas de aprendizaje
- ğŸ¯ Matrices de confusiÃ³n
- ğŸ“‰ ComparaciÃ³n de mÃ©tricas entre diferentes valores de k
- ğŸ”„ DistribuciÃ³n de scores en diferentes folds

## ğŸ”§ CÃ³mo usar este proyecto

### OpciÃ³n 1: VisualizaciÃ³n rÃ¡pida
1. Descarga el archivo [Analisis_Completo_Cross_Validation_KNN.docx](./Analisis_Completo_Cross_Validation_KNN.docx)
2. Revisa el anÃ¡lisis completo con resultados y conclusiones

### OpciÃ³n 2: Ejecutar el cÃ³digo
```bash
# Clonar el repositorio
git clone https://github.com/malurosbolea-ux/Implementation-Cross-Validation-KNN.git

# Navegar al directorio
cd Implementation-Cross-Validation-KNN

# Instalar dependencias
pip install numpy pandas scikit-learn matplotlib seaborn jupyter

# Abrir el notebook
jupyter notebook implementaciÃ³n_cross_validation.ipynb
```

### Dependencias
```python
numpy>=1.19.0
pandas>=1.1.0
scikit-learn>=0.24.0
matplotlib>=3.3.0
seaborn>=0.11.0
jupyter>=1.0.0
```

## ğŸ’¼ Aplicaciones prÃ¡cticas

Este tipo de anÃ¡lisis con K-NN y cross-validation es aplicable a:

- ğŸ¥ **DiagnÃ³stico mÃ©dico**: ClasificaciÃ³n de enfermedades basÃ¡ndose en sÃ­ntomas
- ğŸ›ï¸ **Sistemas de recomendaciÃ³n**: Encontrar productos similares
- ğŸ­ **Reconocimiento de patrones**: IdentificaciÃ³n de imÃ¡genes o texto
- ğŸ“Š **AnÃ¡lisis de clientes**: SegmentaciÃ³n y perfilado
- ğŸ” **DetecciÃ³n de anomalÃ­as**: Identificar comportamientos inusuales

## ğŸ“š Conceptos clave aprendidos

- Funcionamiento del algoritmo K-Nearest Neighbors
- Importancia de la selecciÃ³n de hiperparÃ¡metros
- ImplementaciÃ³n prÃ¡ctica de validaciÃ³n cruzada
- InterpretaciÃ³n de mÃ©tricas de clasificaciÃ³n
- AnÃ¡lisis del trade-off sesgo-varianza
- Mejores prÃ¡cticas en evaluaciÃ³n de modelos de ML

## ğŸ“ Referencias y recursos

- [Scikit-learn Documentation - KNN](https://scikit-learn.org/stable/modules/neighbors.html)
- [Cross-Validation Guide](https://scikit-learn.org/stable/modules/cross_validation.html)
- [Iris Dataset Information](https://archive.ics.uci.edu/ml/datasets/iris)

## ğŸ‘©â€ğŸ’» Autora

**MarÃ­a Luisa Ros Bolea**

Graduada en ComunicaciÃ³n Digital | Especialista en Big Data e Inteligencia Artificial

- ğŸ“§ Email: malurosbolea@gmail.com
- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/marÃ­a-luisa-ros-bolea-400780160/)
- ğŸ™ [GitHub](https://github.com/malurosbolea-ux)
- ğŸŒ [Portfolio](https://marialuisarosboleaportfolio.my.canva.site/porfolio-profesional-mar-a-luisa-ros-bolea-actualizado)

---

<div align="center">

### â­ Si este proyecto te resulta Ãºtil, Â¡dale una estrella!

**Hecho con ğŸ’œ y Python**

</div>
